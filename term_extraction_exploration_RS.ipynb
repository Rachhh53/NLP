{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rachhh53/NLP/blob/main/term_extraction_exploration_RS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiJPRXtNn7V2"
      },
      "source": [
        "# Exploring Term Extraction Methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installs, Imports, Downloads"
      ],
      "metadata": {
        "id": "Ak6NTSYcqUdC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YwmGD1cn7V4",
        "outputId": "89c1dedd-9ef2-4c94-8a82-476dcb534447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: phrasemachine in /usr/local/lib/python3.7/dist-packages (1.0.7)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from phrasemachine) (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->phrasemachine) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->phrasemachine) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->phrasemachine) (4.64.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->phrasemachine) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rake_nltk in /usr/local/lib/python3.7/dist-packages (1.0.6)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.7/dist-packages (from rake_nltk) (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.64.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "#Just in case you need to install the appropriate packages uncomment these lines\n",
        "!pip3 install phrasemachine\n",
        "!pip3 install nltk\n",
        "!pip3 install rake_nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "WaDxeQX6n7V6"
      },
      "outputs": [],
      "source": [
        "import phrasemachine\n",
        "import nltk\n",
        "from rake_nltk import Rake\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk import ngrams, FreqDist\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1snfldg3n7V6",
        "outputId": "457ea7bc-270d-4c51-aee5-d356d247970e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Only run this once, they will be downloaded.\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys \n",
        "\n",
        "stdoutOrigin=sys.stdout \n",
        "sys.stdout = open(\"log.txt\", \"a\")"
      ],
      "metadata": {
        "id": "br3a29AZGmn3"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze Documents"
      ],
      "metadata": {
        "id": "OZjzRKLFqegt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('RSV_Movie_Reviews.csv')\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4OHlDwjpr_OX",
        "outputId": "75f389a7-f625-44e5-9681-60bd0f54c60b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  FileName                                        MovieReview\n",
              "0  RSV_Doc1_MinorityReport  Steven Spielberg’s Minority Report realizes th...\n",
              "1  RSV_Doc2_MinorityReport  In the movie it’s the future (2054) and we now...\n",
              "2  RSV_Doc3_MinorityReport  In the year 2054, at the Department of Precrim...\n",
              "3  RSV_Doc4_MinorityReport  “Minority Report” is the most un-Spielberg fil...\n",
              "4  RSV_Doc5_MinorityReport  Steven Spielberg's Minority Report is a busy f..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf389985-5aed-499a-b642-902547efa80c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FileName</th>\n",
              "      <th>MovieReview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RSV_Doc1_MinorityReport</td>\n",
              "      <td>Steven Spielberg’s Minority Report realizes th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RSV_Doc2_MinorityReport</td>\n",
              "      <td>In the movie it’s the future (2054) and we now...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RSV_Doc3_MinorityReport</td>\n",
              "      <td>In the year 2054, at the Department of Precrim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RSV_Doc4_MinorityReport</td>\n",
              "      <td>“Minority Report” is the most un-Spielberg fil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RSV_Doc5_MinorityReport</td>\n",
              "      <td>Steven Spielberg's Minority Report is a busy f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf389985-5aed-499a-b642-902547efa80c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf389985-5aed-499a-b642-902547efa80c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf389985-5aed-499a-b642-902547efa80c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "-BqN37QDn7V7"
      },
      "outputs": [],
      "source": [
        "# Examples\n",
        "document1 = \"Ruth Bader Ginsburg was the second woman appointed to the United States Supreme Court, but she’s probably the first justice to become a full-fledged pop-cultural phenomenon. “RBG,” a loving and informative documentary portrait of Justice Ginsburg during her 85th year on earth and her 25th on the bench, is both evidence of this status and a partial explanation of how it came about.Directed by Betsy West and Julie Cohen, the film is a jaunty assemblage of interviews, public appearances and archival material, organized to illuminate its subject’s temperament and her accomplishments so far. Though it begins with audio snippets of Justice Ginsburg’s right-wing detractors — who see her as a “demon,” a “devil” and a threat to America — “RBG” takes a pointedly high road through recent political controversies. Its celebration of Justice Ginsburg’s record of progressive activism and jurisprudence is partisan but not especially polemical. The filmmakers share her convictions and assume that the audience will, too. Which might be true, and not only because much of the audience is likely to consist of liberals. Before she was named to the federal bench by Jimmy Carter in 1980, the future justice had argued a handful of important sex-discrimination cases in front of the Supreme Court. What linked these cases — she won five out of six — was the theory that the equal protection clause of the 14th Amendment should apply to women and could be used to remedy discrepancies in hiring, business practices and public policy.The idea that women are equal citizens — that barring them from certain jobs and educational opportunities and treating them as the social inferiors of men are unfair — may not seem especially controversial now. “RBG” uses Justice Ginsburg’s own experiences to emphasize how different things were not so long ago. At Harvard Law School, she was one of nine women in a class of hundreds, and was asked by the dean (as all the women were) why she thought she deserved to take what should have been a man’s place.The biographical part of “RBG” tells a story that is both typical and exceptional. It’s a reminder that the upward striving of first- and second-generation Jewish immigrants in the middle decades of the 20th century was accompanied by fervent political idealism. Justice Ginsburg’s career was marked by intense intellectual ambition and also by a determination to use the law as an instrument of change.The film also chronicles her marriage to Martin Ginsburg. They met as undergraduates at Cornell, and for the next 63 years, Mr. Ginsburg (who died in 2010) was his wife’s tireless supporter and champion, a man whose commitment to domestic egalitarianism was extraordinary in his time and far from common today. As their friends and children explain — and as Mr. Ginsburg, a New York tax lawyer, often said himself — he was responsible for cooking meals and cracking jokes while she was making history. He also, when Byron White retired from the Supreme Court, made sure that her name was high on President Clinton’s list of candidates.It would be fascinating to learn more about that campaign, and also to have a finer-grained sense of the institutional and interpersonal dynamics of the court over the past quarter-century. But “RBG” reasonably chooses to focus on Justice Ginsburg herself, and relishes every moment of her company. It also shows why she has become such an inspiration for younger feminists, like Irin Carmon and Shana Knizhnik, whose 2015 book “Notorious RBG: The Life and Times of Ruth Bader Ginsburg” helped created the contemporary image of a fierce, uncompromising and gracious champion of women’s rights.That those rights are in a new phase of embattlement goes without saying. The movie’s touch is light and its spirit buoyant, but there is no mistaking its seriousness or its passion. Those qualities resonate powerfully in the dissents that may prove to be Justice Ginsburg’s most enduring legacy, and “RBG” is, above all, a tribute to her voice.\"\n",
        "#Add document variables here or parse your documents from a directory (your choice)\n",
        "doc1 = df.iat[0,1]\n",
        "doc2 = df.iat[1,1]\n",
        "doc3 = df.iat[2,1]\n",
        "doc4 = df.iat[3,1]\n",
        "doc5 = df.iat[4,1]\n",
        "doc6 = df.iat[5,1]\n",
        "doc7 = df.iat[6,1]\n",
        "doc8 = df.iat[7,1]\n",
        "doc9 = df.iat[8,1]\n",
        "doc10 = df.iat[9,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "i05dFvTkn7V9"
      },
      "outputs": [],
      "source": [
        "# Create a list of stop words from nltk\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9wMUrVNFn7V9"
      },
      "outputs": [],
      "source": [
        "# Pre-process dataset to remove punctuation\n",
        "def remove_punctuation(in_text):\n",
        "    # Remove punctuation\n",
        "    text = re.sub('[^a-zA-Z]', ' ', str(in_text))\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yqEh9wlRn7V9"
      },
      "outputs": [],
      "source": [
        "# Pre-process dataset to lower case it\n",
        "def lower_case(in_text):\n",
        "    # Convert to lowercase\n",
        "    text = in_text.lower()    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "iQPO6AfYn7V-"
      },
      "outputs": [],
      "source": [
        "# Pre-process dataset to remove tags\n",
        "def remove_tags(in_text):    \n",
        "    # Remove tags\n",
        "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",in_text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "c48j_11_n7V-"
      },
      "outputs": [],
      "source": [
        "# Pre-process dataset to remove special characters and digits\n",
        "def remove_special_chars_and_digits(in_text):\n",
        "    # Remove special characters and digits\n",
        "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",in_text)\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nb8L_hPAn7V_"
      },
      "outputs": [],
      "source": [
        "# Pre-process dataset to appy Stemming\n",
        "def apply_stemming(in_text):\n",
        "    stemmer=PorterStemmer()\n",
        "    word_list = nltk.word_tokenize(in_text)\n",
        "    output = ' '.join([stemmer.stem(w) for w in word_list])\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "fzBJnNMHn7V_"
      },
      "outputs": [],
      "source": [
        "# Pre-process dataset to apply Lemmatization\n",
        "def apply_lemmatization(in_text):\n",
        "    # Lemmatization\n",
        "    lem = WordNetLemmatizer()\n",
        "    word_list = nltk.word_tokenize(in_text)\n",
        "    output = ' '.join([lem.lemmatize(w) for w in word_list])\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TurEXXazn7WA"
      },
      "outputs": [],
      "source": [
        "# Remove stop words\n",
        "def remove_stop_words(in_text):\n",
        "    stop_words = set(stopwords.words('english')) \n",
        "    word_tokens = word_tokenize(in_text)  \n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
        "    filtered_sentence = [] \n",
        "    for w in word_tokens: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w) \n",
        "\n",
        "    return filtered_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Swo3_MUDn7WA"
      },
      "outputs": [],
      "source": [
        "# Run Phase Machine\n",
        "def run_phrase_machine(in_text):\n",
        "    phrases=phrasemachine.get_phrases(in_text)\n",
        "    return phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "296-e6hrn7WA"
      },
      "outputs": [],
      "source": [
        "#Run Rake Keyword Extractor\n",
        "def run_rake(in_text):\n",
        "    r = Rake()\n",
        "    r.extract_keywords_from_text(in_text)\n",
        "    rake_phrases= r.get_ranked_phrases()\n",
        "    return rake_phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "CNTRMLYWn7WB"
      },
      "outputs": [],
      "source": [
        "# Run NLTK Tokenizer\n",
        "def run_nltk_tokenizer(in_text):\n",
        "    tokens=nltk.word_tokenize(in_text)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "9rbtP845n7WB"
      },
      "outputs": [],
      "source": [
        "# Run NLTK Sentence Tokenizer\n",
        "def run_nltk_sent_tokenizer(in_corpus):\n",
        "    sents = nltk.sent_tokenize(in_corpus)\n",
        "    return sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "toBcb9eHn7WB"
      },
      "outputs": [],
      "source": [
        "#Run word-ngram Tokenizer\n",
        "def run_nltk_tokenizer_word_ngrams(in_text, ngram_size):\n",
        "    n_grams = ngrams(nltk.word_tokenize(in_text), ngram_size)\n",
        "    return [ ' '.join(grams) for grams in n_grams]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Knt9-prsn7WC"
      },
      "outputs": [],
      "source": [
        "#Get Frequ Dist \n",
        "def get_freq_dist(terms):\n",
        "    all_counts = dict()\n",
        "    all_counts = FreqDist(terms)\n",
        "    return all_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "yOE3tiR0n7WC"
      },
      "outputs": [],
      "source": [
        "#Explore different extractors and difference preprocessing techniques\n",
        "def explore_extractors(sentences):\n",
        "  # this is going to be too long for console so write it to a file\n",
        "  for sentence in sentences:\n",
        "      print(sentence)\n",
        "      print(\"===================NLTK Tokenizer===================\")\n",
        "      print(run_nltk_tokenizer(sentence))\n",
        "      print(\"\\n===================NLTK Word NGRAM Tokenizer 2 words===================\")\n",
        "      print(run_nltk_tokenizer_word_ngrams(sentence,2))\n",
        "      print(\"\\n===================NLTK Word NGRAM Tokenizer 3 words===================\")\n",
        "      print(run_nltk_tokenizer_word_ngrams(sentence,3))\n",
        "      print(\"\\n===================Phrase Machine===================\")\n",
        "      phrases=run_phrase_machine(sentence)\n",
        "      for term in phrases[\"counts\"].keys():\n",
        "          print(term)\n",
        "      print(\"\\n===================Rake===================\")\n",
        "      print(run_rake(sentence))\n",
        "      print(\"\\n===================NLTK Tokenizer===================\")\n",
        "      print(run_nltk_tokenizer((sentence)))\n",
        "      print(\"\\n===================NLTK Tokenizer LOWER CASE===================\")\n",
        "      print(run_nltk_tokenizer(lower_case(sentence)))\n",
        "      print(\"\\n===================NLTK Tokenizer REMOVE STOP WORDS===================\")\n",
        "      print(remove_stop_words(sentence))   \n",
        "      print(\"\\n===================NLTK Tokenizer REMOVED PUNCTUATION===================\")\n",
        "      print(run_nltk_tokenizer(remove_punctuation(sentence)))\n",
        "      print(\"\\n===================NLTK Tokenizer REMOVED TAGS===================\")\n",
        "      print(run_nltk_tokenizer(remove_tags(sentence)))\n",
        "      print(\"\\n===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\")\n",
        "      print(run_nltk_tokenizer(remove_special_chars_and_digits(sentence)))\n",
        "      print(\"\\n===================NLTK Tokenizer STEMMING APPLIED===================\")\n",
        "      print(run_nltk_tokenizer(apply_stemming(sentence)))\n",
        "      print(\"\\n===================NLTK Tokenizer LEMMATIZATION APPLIED===================\")\n",
        "      print(run_nltk_tokenizer(apply_lemmatization(sentence)))\n",
        "      #break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "6kxxSnZUn7WD"
      },
      "outputs": [],
      "source": [
        "#Explore different extractors and difference preprocessing techniques\n",
        "def explore_terms(sentences):\n",
        "  all_terms=[]\n",
        "  for sentence in sentences:\n",
        "      print(sentence)\n",
        "      #pick your favorite term extractor\n",
        "      all_terms = all_terms +run_rake(sentence)\n",
        "  #get the frequency distribution across the terms\n",
        "  fd=get_freq_dist(all_terms)\n",
        "  fd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "nYOYdCVQn7WC"
      },
      "outputs": [],
      "source": [
        "for index, row in df.iterrows():\n",
        "  print(\"/n======================\", row['FileName'], \"====================\")\n",
        "  #Run this first to get sentences from text.\n",
        "  sents=run_nltk_sent_tokenizer(row['MovieReview'])\n",
        "  explore_extractors(sents)\n",
        "  explore_terms(sents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.stdout.close()\n",
        "sys.stdout=stdoutOrigin"
      ],
      "metadata": {
        "id": "GfPNo27hw_26"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ir7jjkyOG9Ay"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "term_extraction_exploration_RS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}